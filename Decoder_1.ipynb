{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4649920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2c46dc",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9827fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kawaii/opt/miniconda3/envs/transformers/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55021640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration cfilt--iitb-english-hindi-911387c6837f8b91\n",
      "Reusing dataset parquet (/Users/kawaii/.cache/huggingface/datasets/parquet/cfilt--iitb-english-hindi-911387c6837f8b91/0.0.0/1638526fd0e8d960534e2155dc54fdff8dce73851f21f031d2fb9c2cf757c121)\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 37.96it/s]\n",
      "100%|████████████████████████████| 1659083/1659083 [00:00<00:00, 2099857.38it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"cfilt/iitb-english-hindi\")\n",
    "list_dataset = dataset['train']['translation']\n",
    "english_sent = []\n",
    "hindi_sent = []\n",
    "\n",
    "for i in tqdm(range(len(list_dataset))):\n",
    "    english_sent.append(list_dataset[i]['en'])\n",
    "    hindi_sent.append(list_dataset[i]['hi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476f8e94",
   "metadata": {},
   "source": [
    "# MURIL Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a505a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6dd1261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 00:38:21.135582: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "preprocessor = hub.load(\"https://tfhub.dev/google/MuRIL_preprocess/1\")\n",
    "tokenizer = hub.KerasLayer(preprocessor.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d17aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_sentence(tokenizer, string):    \n",
    "    text_input = tf.constant([string])\n",
    "    tokens = tokenizer(text_input)\n",
    "    \n",
    "    return tokens    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e683fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = get_tokenized_sentence(tokenizer=tokenizer, string='This is a sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043a73db",
   "metadata": {},
   "source": [
    "# MURIL Decoder Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8e65f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder_input(preprocessor, text_input):\n",
    "    text_input = tf.constant([text_input])\n",
    "    return preprocessor(text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c49ee23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_inp = get_decoder_input(preprocessor=preprocessor, text_input = 'This is a sentence' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "888a884b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       "array([[  104,  1475,  1121,   172, 30936,   105,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_inp['input_word_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79b02906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  104  1475  1121   172 30936     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0], shape=(128,), dtype=int32)\n",
      "<tf.RaggedTensor [[1475, 1121, 172, 30936, 105, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]>\n"
     ]
    }
   ],
   "source": [
    "tokenized_sent = []\n",
    "sent = np.array(dec_inp['input_word_ids'])\n",
    "for token in sent[0]:\n",
    "    if token != 0:\n",
    "        tokenized_sent.append(token)\n",
    "        \n",
    "inputs = tokenized_sent[:-1]\n",
    "labels = tokenized_sent[1:]\n",
    "\n",
    "for i in range(128 - len(labels)):\n",
    "    inputs.append(0)\n",
    "    labels.append(0)\n",
    "    \n",
    "\n",
    "inputs = tf.ragged.constant(inputs)\n",
    "labels = tf.ragged.constant([labels])\n",
    "\n",
    "print(inputs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8b6937",
   "metadata": {},
   "source": [
    "# Positional Embedding and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b689622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    depth = depth/2\n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth\n",
    "    \n",
    "    angle_rates = 1 / (10000**depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    \n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis = -1)\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a744017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero = True)\n",
    "        self.pos_encoding = positional_encoding(length = 2048, depth = d_model)\n",
    "        \n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        return self.embedding.compute_mask(*args, **kwargs)\n",
    "    \n",
    "    def call(self, x):\n",
    "        length = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e692e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False]])>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_embedding = PositionalEmbedding(vocab_size = 80000, d_model = 512)\n",
    "\n",
    "eng_embedding(np.array([inputs]))._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba60e09",
   "metadata": {},
   "source": [
    "# Base Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eaae9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52c77a",
   "metadata": {},
   "source": [
    "# Cross Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4701d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, context):\n",
    "        attn_output, attn_scores = self.mha(query = x,\n",
    "                                            key = context,\n",
    "                                            value = context,\n",
    "                                            return_attention_scores = True)\n",
    "        \n",
    "        self.last_attn_scores = attn_scores\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "598bc0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ca = CrossAttention(num_heads = 2, key_dim = 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f2b022",
   "metadata": {},
   "source": [
    "# Casual Self Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49e91972",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CasualSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(query = x,\n",
    "                               value = x,\n",
    "                               key = x,\n",
    "                               use_casual_mask = True)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b092c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_csa = CasualSelfAttention(num_heads = 2, key_dim = 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928523dd",
   "metadata": {},
   "source": [
    "# Feed Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab459cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate = 0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation = 'relu'),\n",
    "            tf.keras.layers.Dense(d_model),\n",
    "            tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        \n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7670bd1",
   "metadata": {},
   "source": [
    "# Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be070d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, d_model, num_heads, dff, dropout_rate = 0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.casual_self_attention = CasualSelfAttention(\n",
    "                                        num_heads = num_heads,\n",
    "                                        key_dim = d_model,\n",
    "                                        dropout = dropout_rate)\n",
    "        \n",
    "        self.cross_attention = CrossAttention(\n",
    "                                num_heads = num_heads,\n",
    "                                key_dim = d_model,\n",
    "                                dropout = dropout_rate)\n",
    "        \n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "        \n",
    "    def call(self, x, context):\n",
    "        x = self.casual_self_attention(x = x)\n",
    "        x = self.cross_attention(x = x, context = context)\n",
    "        \n",
    "        #cache the last attention to plot\n",
    "        self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "        \n",
    "        #Shape (batch_size, seq_len, d_model)\n",
    "        x = self.ffn(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f115afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_decoder_layer = DecoderLayer(d_model = 512, num_heads = 8, dff = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14dbfeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DecoderLayer at 0x30c0bbe50>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506c9993",
   "metadata": {},
   "source": [
    "# The Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6ff943ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
    "                 vocab_size, dropout_rate = 0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size = vocab_size,\n",
    "                                                d_model = d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(d_model = d_model, num_heads = num_heads,\n",
    "                        dff = dff, dropout_rate = dropout_rate)\n",
    "            for _ in range(num_layers)]\n",
    "        \n",
    "        self.last_attn_scores = None\n",
    "        \n",
    "    def call(self, x, context):\n",
    "        x = self.pos_embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, context)\n",
    "            \n",
    "        self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7a75fa5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([inputs]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6cbde29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.ones(128)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0702e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_decoder = Decoder(num_layers = 4,\n",
    "                         d_model = 512,\n",
    "                         num_heads = 8,\n",
    "                         dff = 2048,\n",
    "                         vocab_size = 80000)\n",
    "\n",
    "output = sample_decoder(x = np.array([inputs])\n",
    "                        context = #output of the encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
